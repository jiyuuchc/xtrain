{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#training-backends","title":"Training backends","text":"class description xtrain.Core No model JIT compiling, i.e., for debugging xtrain.JIT JIT compile the model. Default strategy xtrain.Distributed Transform the model with pmap. This allows training the model on multiple devices."},{"location":"#xtrain.Trainer","title":"<code>xtrain.Trainer</code>  <code>dataclass</code>","text":"<p>A general purpose FLAX model trainer. Help avoiding most of the biolerplate code when trainning with FLAX.</p> <p>Attributes:</p> Name Type Description <code>model</code> <code>Module</code> <p>A Flax module</p> <code>losses</code> <code>LOSSES</code> <p>A collection of loss function ( loss_fn(batch:Any, prediction:Any)-&gt;float ).</p> <code>optimizer</code> <code>Optimizer</code> <p>An optax optimizer</p> <code>seed</code> <code>int | RNG</code> <p>RNG seed</p> <code>strategy</code> <code>type</code> <p>a training strategy type</p> <p>Example:</p> <pre><code>```\ntrainer = lacss.train.Trainer(my_module, my_loss_func)\n\ntrain_it = trainer.train(my_dataset)\n\nfor k in range(train_steps):\n    _ = next(train_it)\n    if k % 1000 == 0:\n        print(train_it.loss_logs)\n        train_it.reset_loss_logs()\n```\n</code></pre>"},{"location":"#xtrain.Trainer.compute_metrics","title":"<code>compute_metrics(*args, **kwargs)</code>","text":"<p>A convient function to compute all metrics. See test() fucntion</p> <p>Returns:</p> Type Description <code>dict</code> <p>A metric dict. Keys are metric names.</p>"},{"location":"#xtrain.Trainer.predict","title":"<code>predict(dataset, variables, strategy=None, method=None, **kwargs)</code>","text":"<p>Create predictor iterator.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Iterable</code> <p>An iterator or iterable to supply the input data.</p> required <code>variables</code> <code>dict</code> <p>Model weights etc. typically get from TrainIterator</p> required <code>strategy</code> <code>type | None</code> <p>Optionally override the default backend.</p> <code>None</code> <p>Returns:</p> Type Description <p>An iterator. Stepping through it will produce model predictions</p>"},{"location":"#xtrain.Trainer.test","title":"<code>test(dataset, metrics, variables, strategy=None, method=None, **kwargs)</code>","text":"<p>Create test/validation iterator.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Iterable</code> <p>An iterator or iterable to supply the testing data. The iterator should yield a tupple of (inputs, labels).</p> required <code>metrics</code> <code>METRICS</code> <p>A list of Metric objects. They should have two functions: m.update(preds, **kwargs):     preds is the model output. the remaining kwargs are content of     labels. m.compute():     which should return the accumulated metric value.</p> required <code>variables</code> <code>dict</code> <p>Model weights etc. typically get from TrainIterator</p> required <code>strategy</code> <code>type | None</code> <p>Optionally override the default strategy.</p> <code>None</code> <p>Returns:</p> Type Description <code>Iterator</code> <p>An iterator. Stepping through it will drive the updating of each metric obj. The iterator itself return the list of metrics.</p>"},{"location":"#xtrain.Trainer.train","title":"<code>train(dataset, *, strategy=None, rng_cols=['dropout'], init_vars=None, frozen=None, method=None, **kwargs)</code>","text":"<p>Create the training iterator</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Iterable</code> <p>An iterator or iterable to supply the training data. The dataset should produce <code>(inputs, labels, sample_weight)</code>, however both the labels and the sample_weight are optional. The inputs is either a list  (not tuple) or a dict. If latter, the keys are interpreted as the names for keyword args of the model's call function. </p> required <code>strategy</code> <code>type | None</code> <p>Optionally override the default strategy.</p> <code>None</code> <code>rng_cols</code> <code>Sequence[str]</code> <p>Names of any RNG used by the model. Should be a list of strings.</p> <code>['dropout']</code> <code>init_vars</code> <code>dict | None</code> <p>optional variables to initialize model</p> <code>None</code> <code>frozen</code> <code>dict | None</code> <p>a bool pytree (matching model parameter tree) indicating frozen parameters.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyward args passed to the model. E.g. \"training=True\"</p> <code>{}</code> <p>Returns:</p> Type Description <code>TrainIterator</code> <p>TrainIterator. Stepping through the iterator will train the model.</p>"},{"location":"#xtrain.TFDatasetAdapter","title":"<code>xtrain.TFDatasetAdapter</code>","text":"<p>Convert <code>tf.data.Dataset</code> into a python iterable suitable for lacss.train.Trainer</p> <pre><code>my_dataset = TFDatasetAdapter(my_tf_dataset)\n</code></pre>"},{"location":"#xtrain.TorchDataLoaderAdapter","title":"<code>xtrain.TorchDataLoaderAdapter</code>","text":"<p>Convert torch dataloader into a python iterable suitable for lacss.Trainer</p> <pre><code>my_dataset = TorchDataLoaderAdapter(my_torch_dataloader)\n</code></pre>"},{"location":"#xtrain.GeneratorAdapter","title":"<code>xtrain.GeneratorAdapter</code>","text":"<p>Convert a python generator function to a python iterable suitable for lacss.train.Trainer with an option to prefetch data.</p>"}]}